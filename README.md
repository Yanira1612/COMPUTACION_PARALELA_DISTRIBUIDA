# COMPUTACION_PARALELA_DISTRIBUIDA

### 3.1 Histograma Paralelo
Implementaci칩n de un programa paralelo para calcular un histograma. El proceso 0 lee un conjunto de datos y lo distribuye entre los procesos. Cada proceso calcula los conteos de los intervalos en sus datos locales, y el proceso 0 recopila y muestra el histograma final.

### 3.2 Lanzamiento de dardos
Este programa estima el valor de  lanzando "dardos" a una cuadr칤cula. Cada proceso genera coordenadas aleatorias dentro de un cuadrado y cuenta cu치ntos puntos caen dentro del c칤rculo inscrito. El proceso 0 recopila los resultados de todos los procesos para calcular una estimaci칩n de  utilizando la proporci칩n de puntos en el c칤rculo respecto al total.

### 3.3 A - Suma global potencia 2
La implementaci칩n consiste en un programa que calcula la suma global de manera eficiente utilizando una estructura de 치rbol binario. En este enfoque, cada proceso del sistema calcula su propia suma local. Luego, mediante una comunicaci칩n en pares, los procesos env칤an y reciben sus sumas entre s칤, lo que permite reducir gradualmente el total hasta que solo el proceso ra칤z tiene la suma global final.

### 3.3 B - Suma global 
El programa est치 dise침ado para funcionar con cualquier cantidad de procesos, incluyendo aquellos casos en los que el n칰mero total de procesos no es una potencia de dos. En situaciones donde hay un n칰mero impar de procesos, el proceso ra칤z se encarga de recibir las sumas de los procesos que no tienen un par correspondiente, garantizando as칤 que todos los procesos contribuyan al resultado final.

### 3.5 -  Multiplicaci칩n Matriz-Vector
Este programa realiza la multiplicaci칩n de una matriz cuadrada de orden 洧녵 y un vector mediante una distribuci칩n de bloques de columnas en un entorno paralelo utilizando MPI. El proceso con rango 0 es responsable de leer los elementos de la matriz y el vector desde la entrada. Luego, el vector se distribuye a todos los procesos a trav칠s de la funci칩n MPI_Bcast. La matriz se divide en partes iguales, enviando a cada proceso una secci칩n de la matriz mediante MPI_Scatter.

Cada proceso lleva a cabo la multiplicaci칩n de su bloque de filas de la matriz con el vector recibido, almacenando los resultados locales en un vector. Finalmente, los resultados locales se recopilan en el proceso 0 utilizando MPI_Gather, que muestra el resultado final de la multiplicaci칩n de matriz y vector. 

### 3.8 - Merge Sort Paralelo
El programa realiza un ordenamiento por mezcla en paralelo, comenzando con un conjunto de claves asignadas a cada proceso. El proceso con rango 0 solicita el tama침o total de la lista y lo distribuye a los dem치s procesos. Cada proceso genera una lista local de enteros aleatorios, que se ordena utilizando la funci칩n std::sort. Luego, los procesos muestran sus listas ordenadas locales.

La fusi칩n de listas se lleva a cabo mediante una comunicaci칩n estructurada en forma de 치rbol. Los procesos con rango par reciben listas de otros procesos, fusionando estas listas en su propia lista ordenada. Los procesos con rango impar env칤an sus listas a procesos de rango par. Este proceso se repite en varias etapas hasta que todos los elementos est치n ordenados y se recopilan en el proceso 0.
